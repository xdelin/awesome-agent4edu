import json
import os
import re
import datetime

# Define paths
skills_json_path = 'src/data/skills.json'
output_dir = '../awesome-education-mcp'
md_cn_path = os.path.join(output_dir, 'CLAUDE_SKILLS.md')
md_en_path = os.path.join(output_dir, 'CLAUDE_SKILLS_EN.md')
readme_cn_path = os.path.join(output_dir, 'README_CN.md')
readme_en_path = os.path.join(output_dir, 'README.md')

# Emoji Map
emoji_map = {
    "Education & Tutoring": "ğŸ«",
    "Academic & Writing": "ğŸ“š",
    "Coding & Data": "ğŸ’»",
    "Visual & Presentation": "ğŸ¨",
    "Productivity & Career": "ğŸ§ ",
    "MCP & Meta Skills": "ğŸ› ï¸"
}

def load_skills():
    with open(skills_json_path, 'r', encoding='utf-8') as f:
        return json.load(f)

def clean_anchor(text):
    # Remove emoji, special chars, keep only alphanumeric and hyphens
    # 1. Remove & 
    text = text.replace("&", "")
    # 2. Replace spaces with hyphens
    text = text.replace(" ", "-")
    # 3. Lowercase
    text = text.lower()
    # 4. Remove any other non-url friendly chars (simple regex)
    text = re.sub(r'[^a-z0-9\-]', '', text)
    # 5. Remove duplicate hyphens
    text = re.sub(r'-+', '-', text)
    return text.strip('-')

def generate_cn_markdown(data):
    # Generates CLAUDE_SKILLS.md (Skills Only)
    content = "# Claude Skills for Education & Learning / æ•™è‚²ä¸å­¦ä¹ ä¸“ç”¨ Claude æŠ€èƒ½åº“\n\n"
    content += "è¿™æ˜¯ä¸€ä¸ªä¸“æ³¨äº **Claude** (ç‰¹åˆ«æ˜¯ Claude 3.5 Sonnet / Opus) åœ¨æ•™è‚²ã€å­¦ä¹ ã€å­¦æœ¯ç ”ç©¶å’Œå­¦ç”Ÿç”Ÿäº§åŠ›æ–¹é¢çš„ **Skills (æŠ€èƒ½) å’Œ Prompts (æç¤ºè¯)** é›†åˆã€‚\n\n"
    content += "å¦‚æœæ‚¨æ­£åœ¨å¯»æ‰¾ MCP æœåŠ¡å™¨å·¥å…·ï¼Œè¯·æŸ¥çœ‹ä¸» [README](./README_CN.md)ã€‚\n\n"
    content += "[English](./CLAUDE_SKILLS_EN.md) | [ä¸­æ–‡](./CLAUDE_SKILLS.md)\n\n"
    content += "## ç›®å½•\n\n"

    # TOC
    for category in data:
        skills = [s for s in category['skills'] if s.get('type') != 'MCP']
        if not skills: continue
        cat_zh = category['category']['zh']
        cat_en = category['category']['en']
        emoji = emoji_map.get(cat_en, "ğŸ“‚")
        anchor = clean_anchor(cat_en)
        content += f"- [{emoji} {cat_zh}](#{anchor})\n"
    
    content += "\n---\n\n"

    for category in data:
        skills = [s for s in category['skills'] if s.get('type') != 'MCP']
        if not skills: continue

        cat_en = category['category']['en']
        cat_zh = category['category']['zh']
        emoji = emoji_map.get(cat_en, "ğŸ“‚")
        anchor = clean_anchor(cat_en)
        
        # Use a hidden span or standard header attribute if possible, but explicit 'a' tag is most reliable for GitHub TOCs with emojis in headers
        content += f"## <a id='{anchor}'></a>{emoji} {cat_en} ({cat_zh})\n\n"
        
        desc_zh = category['description']['zh']
        if desc_zh:
            content += f"> {desc_zh}\n\n"
        
        for skill in skills:
            name = skill['name']
            url = skill['url']
            desc = skill['description']['zh']
            use_case = skill['useCase']['zh']
            
            content += f"- **[{name}]({url})**\n"
            content += f"  - **æè¿°**: {desc}\n"
            content += f"  - **é€‚ç”¨åœºæ™¯**: {use_case}\n\n"
            
    content += "---\n\n"
    content += f"*Last updated/æœ€åæ›´æ–°: {datetime.date.today()}*\n"
    content += "*Note: This file is automatically generated based on GitHub search results.*"
    return content

def generate_en_markdown(data):
    # Generates CLAUDE_SKILLS_EN.md (Skills Only)
    content = "# Claude Skills for Education & Learning\n\n"
    content += "A collection of **Skills and Prompts** focused on **Claude** (specifically Claude 3.5 Sonnet / Opus) for education, learning, academic research, and student productivity.\n\n"
    content += "If you are looking for MCP Servers, please check the main [README](./README.md).\n\n"
    content += "[English](./CLAUDE_SKILLS_EN.md) | [ä¸­æ–‡](./CLAUDE_SKILLS.md)\n\n"
    content += "## Table of Contents\n\n"

    # TOC
    for category in data:
        skills = [s for s in category['skills'] if s.get('type') != 'MCP']
        if not skills: continue
        cat_en = category['category']['en']
        emoji = emoji_map.get(cat_en, "ğŸ“‚")
        anchor = clean_anchor(cat_en)
        content += f"- [{emoji} {cat_en}](#{anchor})\n"

    content += "\n---\n\n"

    for category in data:
        skills = [s for s in category['skills'] if s.get('type') != 'MCP']
        if not skills: continue

        cat_en = category['category']['en']
        emoji = emoji_map.get(cat_en, "ğŸ“‚")
        anchor = clean_anchor(cat_en)
        
        content += f"## <a id='{anchor}'></a>{emoji} {cat_en}\n\n"
        
        desc_en = category['description']['en']
        if desc_en:
            content += f"> {desc_en}\n\n"
            
        for skill in skills:
            name = skill['name']
            url = skill['url']
            desc = skill['description']['en']
            use_case = skill['useCase']['en']
            
            content += f"- **[{name}]({url})**\n"
            content += f"  - **Description**: {desc}\n"
            content += f"  - **Use Case**: {use_case}\n\n"
            
    content += "---\n\n"
    content += f"*Last updated: {datetime.date.today()}*\n"
    content += "*Note: This file is automatically generated based on GitHub search results.*"
    return content

def generate_readme_cn(data):
    # Generates README_CN.md (MCP Only)
    content = "# Awesome Education MCP / æ•™è‚²é¢†åŸŸ MCP æœåŠ¡å™¨ç²¾é€‰\n\n"
    content += "ç²¾é€‰çš„ **Model Context Protocol (MCP)** æœåŠ¡å™¨åˆ—è¡¨ï¼Œä¸“æ³¨äºæ•™è‚²ã€å­¦æœ¯ç ”ç©¶ã€ç”Ÿäº§åŠ›å’ŒçŸ¥è¯†ç®¡ç†ã€‚\n\n"
    content += "å¦‚æœæ‚¨æ­£åœ¨å¯»æ‰¾ Claude Prompts & Skillsï¼Œè¯·æŸ¥çœ‹ [CLAUDE_SKILLS.md](./CLAUDE_SKILLS.md)ã€‚\n\n"
    content += "[English](./README.md) | [ä¸­æ–‡](./README_CN.md)\n\n"
    content += "## ç›®å½•\n\n"

    # TOC
    for category in data:
        mcps = [s for s in category['skills'] if s.get('type') == 'MCP']
        if not mcps: continue
        cat_zh = category['category']['zh']
        cat_en = category['category']['en']
        emoji = emoji_map.get(cat_en, "ğŸ“‚")
        anchor = clean_anchor(cat_en)
        content += f"- [{emoji} {cat_zh}](#{anchor})\n"
    
    content += "\n---\n\n"

    for category in data:
        mcps = [s for s in category['skills'] if s.get('type') == 'MCP']
        if not mcps: continue

        cat_en = category['category']['en']
        cat_zh = category['category']['zh']
        emoji = emoji_map.get(cat_en, "ğŸ“‚")
        anchor = clean_anchor(cat_en)
        
        content += f"## <a id='{anchor}'></a>{emoji} {cat_en} ({cat_zh})\n\n"
        
        desc_zh = category['description']['zh']
        if desc_zh:
            content += f"> {desc_zh}\n\n"
        
        for skill in mcps:
            name = skill['name']
            url = skill['url']
            desc = skill['description']['zh']
            use_case = skill['useCase']['zh']
            
            content += f"- **[{name}]({url})**\n"
            content += f"  - **æè¿°**: {desc}\n"
            content += f"  - **é€‚ç”¨åœºæ™¯**: {use_case}\n\n"

    content += "---\n\n"
    content += f"*Last updated/æœ€åæ›´æ–°: {datetime.date.today()}*\n"
    return content

def generate_readme_en(data):
    # Generates README.md (MCP Only)
    content = "# Awesome Education MCP\n\n"
    content += "A curated list of **Model Context Protocol (MCP)** servers focused on education, academic research, productivity, and knowledge management.\n\n"
    content += "If you are looking for Claude Prompts & Skills, please check [CLAUDE_SKILLS_EN.md](./CLAUDE_SKILLS_EN.md).\n\n"
    content += "[English](./README.md) | [ä¸­æ–‡](./README_CN.md)\n\n"
    content += "## Table of Contents\n\n"

    # TOC
    for category in data:
        mcps = [s for s in category['skills'] if s.get('type') == 'MCP']
        if not mcps: continue
        cat_en = category['category']['en']
        emoji = emoji_map.get(cat_en, "ğŸ“‚")
        anchor = clean_anchor(cat_en)
        content += f"- [{emoji} {cat_en}](#{anchor})\n"
    
    content += "\n---\n\n"

    for category in data:
        mcps = [s for s in category['skills'] if s.get('type') == 'MCP']
        if not mcps: continue

        cat_en = category['category']['en']
        emoji = emoji_map.get(cat_en, "ğŸ“‚")
        anchor = clean_anchor(cat_en)
        
        content += f"## <a id='{anchor}'></a>{emoji} {cat_en}\n\n"
        
        desc_en = category['description']['en']
        if desc_en:
            content += f"> {desc_en}\n\n"
        
        for skill in mcps:
            name = skill['name']
            url = skill['url']
            desc = skill['description']['en']
            use_case = skill['useCase']['en']
            
            content += f"- **[{name}]({url})**\n"
            content += f"  - **Description**: {desc}\n"
            content += f"  - **Use Case**: {use_case}\n\n"

    content += "---\n\n"
    content += f"*Last updated: {datetime.date.today()}*\n"
    return content

def main():
    data = load_skills()
    
    md_cn = generate_cn_markdown(data)
    with open(md_cn_path, 'w', encoding='utf-8') as f:
        f.write(md_cn)
    print(f"Generated {md_cn_path}")
    
    md_en = generate_en_markdown(data)
    with open(md_en_path, 'w', encoding='utf-8') as f:
        f.write(md_en)
    print(f"Generated {md_en_path}")

    readme_cn = generate_readme_cn(data)
    with open(readme_cn_path, 'w', encoding='utf-8') as f:
        f.write(readme_cn)
    print(f"Generated {readme_cn_path}")

    readme_en = generate_readme_en(data)
    with open(readme_en_path, 'w', encoding='utf-8') as f:
        f.write(readme_en)
    print(f"Generated {readme_en_path}")

if __name__ == "__main__":
    main()
